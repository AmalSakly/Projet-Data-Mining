{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final Project: Sentiment Analysis on Covid-19 Tweets  \n",
    "**Math189Z – Covid-19: Data Analytics and Machine Learning**  \n",
    "Nico Espinosa Dice  \n",
    "*May, 2020*  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sources\n",
    "This project uses theory presented in the following academic papers:  \n",
    "- [Sentiment Analysis of Twitter Data](http://www.cs.columbia.edu/~julia/papers/Agarwaletal11.pdf) (1)\n",
    "\n",
    "- [Sentiment Analysis of Twitter Data](https://arxiv.org/pdf/1711.10377.pdf) (2)\n",
    "\n",
    "- [Covid-19 Tweets Dataset and Statistics](https://ieee-dataport.org/open-access/corona-virus-covid-19-tweets-dataset)\n",
    "\n",
    "\n",
    "This project uses code that was inspired and adapted from the following open-source resources:  \n",
    "- [Twitter Sentiment Analysis with Explanation (Naive Bayes)](https://medium.com/@koshut.takatsuji/twitter-sentiment-analysis-with-full-code-and-explanation-naive-bayes-a380b38f036b)\n",
    "\n",
    "- [Creating The Twitter Sentiment Analysis Program in Python with Naive Bayes Classification](https://towardsdatascience.com/creating-the-twitter-sentiment-analysis-program-in-python-with-naive-bayes-classification-672e5589a7ed)\n",
    "\n",
    "- [How to Do Sentiment Analysis on a Twitter Account](https://medium.com/better-programming/twitter-sentiment-analysis-15d8892c0082)\n",
    "\n",
    "- [Comprehensive Hands on Guide to Twitter Sentiment Analysis with dataset and code](https://www.analyticsvidhya.com/blog/2018/07/hands-on-sentiment-analysis-dataset-python/)\n",
    "\n",
    "### Data\n",
    "The dataset of Tweets was provided by Professor Gu as part of HMC Math189Z. The data is available [here](https://math189covid19.github.io/resources.html). The original source of the data is unknown at this time.\n",
    "\n",
    "The Twitter sentiment corpus was provided in this [public repository](https://github.com/zfz/twitter_corpus).\n",
    "\n",
    "The Covid-19 related data was provided in this [public repository](https://data.humdata.org/dataset/novel-coronavirus-2019-ncov-cases/resource/d037a9e3-69d8-4452-bc51-3e225fca75c3)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports the necessary libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "from textblob import TextBlob\n",
    "import matplotlib.pyplot as plt\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from string import punctuation \n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import preprocessing\n",
    "from collections import Counter\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports data into Pandas dataframe\n",
    "feb_tweets = pd.read_csv('Data/feb_data.csv')\n",
    "march_tweets = pd.read_csv('Data/march_data.csv')\n",
    "april_tweets = pd.read_csv('Data/april_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sets column names of dataframes and drop unnecessary column\n",
    "feb_tweets.columns, march_tweets.columns, april_tweets.columns = ['Number', \"Date\", \"Text\"], ['Number', \"Date\", \"Text\"], ['Number', \"Date\", \"Text\"]\n",
    "feb_tweets = feb_tweets.drop(columns = [\"Number\"])\n",
    "march_tweets = march_tweets.drop(columns = [\"Number\"])\n",
    "april_tweets = april_tweets.drop(columns = [\"Number\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feb_tweets[\"Month\"] = \"February\"\n",
    "march_tweets[\"Month\"] = \"March\"\n",
    "april_april_tweetstweets[\"Month\"] = \"April\"\n",
    "\n",
    "data = pd.concat([feb_tweets, march_tweets, april_tweets], ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feb_tweets.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_stopwords = set(stopwords.words('english') + list(punctuation) + ['AT_USER','URL'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \"cleans\" the text by removing hyperlinks, hashtags, mentions, and retweets\n",
    "# This function was suggested here: https://medium.com/better-programming/twitter-sentiment-analysis-15d8892c0082\n",
    "def cleanText(text):\n",
    "    text = text.lower() # Makes text lowercase\n",
    "    text = re.sub('https?:\\/\\/\\S+', '', text) # Removes hyperlinks\n",
    "    text = re.sub('#', '', text) # Removes hashtags\n",
    "    text = re.sub('@[A-Za-z0–9]+', '', text) # Removes mentions (@)\n",
    "    text = re.sub('RT[\\s]+', '', text) # Removes \"RT\"\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convertToList(text):\n",
    "    text = word_tokenize(text)\n",
    "    return [word for word in text if word not in new_stopwords] # Source for this line: https://towardsdatascience.com/creating-the-twitter-sentiment-analysis-program-in-python-with-naive-bayes-classification-672e5589a7ed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Applys cleanText() to every Tweet in dataframe\n",
    "data[\"Text\"] = data[\"Text\"].apply(cleanText)\n",
    "data[\"List of Words\"] = data[\"Text\"].apply(convertToList)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleanDate(date):\n",
    "    month = date[5:7]\n",
    "    day = date[8:10]\n",
    "    \n",
    "    if month[0] == \"0\":\n",
    "        month = month[1]\n",
    "    if day[0] == \"0\":\n",
    "        day = day[1]\n",
    "    \n",
    "    return month + \"/\" + day + \"/20\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"Date\"] = data[\"Date\"].apply(cleanDate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Polarity\n",
    "-1 → extreme negative,  \n",
    "0 → neutral,  \n",
    "1 → extreme positive."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Returns the polarity of the Tweet's text\n",
    "def getPolarity(text):\n",
    "   return  TextBlob(text).sentiment.polarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creates a new column containing the subjectivity of every Tweet\n",
    "data['Polarity'] = data['Text'].apply(getPolarity)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Subjectivity\n",
    "0 → fact,  \n",
    "1 → opinion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Returns the subjectivity of the Tweet's text\n",
    "def getSubjectivity(text):\n",
    "   return TextBlob(text).sentiment.subjectivity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creates a new column containing the subjectivity of every Tweet\n",
    "data[\"Subjectivity\"] = data[\"Text\"].apply(getSubjectivity)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sentiment Analysis\n",
    "Polarity < 0 → negative,  \n",
    "Polarity == 0 → neutral,  \n",
    "Polarity > 0 → positive. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Returns the analysis of each Tweet's text\n",
    "def getSentiment(polarity):\n",
    "    if polarity < 0:\n",
    "      return 'Negative'\n",
    "    elif polarity == 0:\n",
    "      return 'Neutral'\n",
    "    else:\n",
    "      return 'Positive'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['Analysis'] = data['Polarity'].apply(getSentiment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analysis: Full Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "positive_tweets = data.loc[data[\"Analysis\"] == \"Positive\"]\n",
    "neutral_tweets = data.loc[data[\"Analysis\"] == \"Neutral\"]\n",
    "negative_tweets = data.loc[data[\"Analysis\"] == \"Negative\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "positive_tweets.reset_index(drop=True, inplace=True)\n",
    "neutral_tweets.reset_index(drop=True, inplace=True)\n",
    "negative_tweets.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "positive_tweets.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "neutral_tweets[\"Text\"].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "negative_tweets.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Positive Tweets\n",
    "plt.scatter(positive_tweets[\"Polarity\"], positive_tweets[\"Subjectivity\"])\n",
    "\n",
    "plt.title('Sentiment Analysis of Positive Tweets') \n",
    "plt.xlabel('Polarity') \n",
    "plt.ylabel('Subjectivity') \n",
    "plt.show()\n",
    "\n",
    "# Neutral Tweets\n",
    "plt.scatter(neutral_tweets[\"Polarity\"], neutral_tweets[\"Subjectivity\"])\n",
    "\n",
    "plt.title('Sentiment Analysis of Neutral Tweets') \n",
    "plt.xlabel('Polarity') \n",
    "plt.ylabel('Subjectivity') \n",
    "plt.show()\n",
    "\n",
    "# Negative Tweets\n",
    "plt.scatter(negative_tweets[\"Polarity\"], negative_tweets[\"Subjectivity\"])\n",
    "\n",
    "plt.title('Sentiment Analysis of Negative Tweets') \n",
    "plt.xlabel('Polarity') \n",
    "plt.ylabel('Subjectivity')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(data[\"Analysis\"].value_counts())\n",
    "print(\"Total:\", data.shape[0])\n",
    "print()\n",
    "\n",
    "print(\"Percentage of positive Tweets:\", (positive_tweets.shape[0] / data.shape[0]))\n",
    "print()\n",
    "\n",
    "print(\"Percentage of neutral Tweets:\", (neutral_tweets.shape[0] / data.shape[0]))\n",
    "print()\n",
    "\n",
    "print(\"Percentage of negative Tweets:\", (negative_tweets.shape[0] / data.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.title(\"Sentiment Analysis: Full Dataset\")\n",
    "plt.xlabel(\"Sentiment\")\n",
    "plt.ylabel(\"Number of Tweets\")\n",
    "data[\"Analysis\"].value_counts().plot(kind = \"bar\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.title(\"Sentiment Analysis (Percentage): Full Dataset\")\n",
    "plt.xlabel(\"Sentiment\")\n",
    "plt.ylabel(\"Percentage of Total Tweets\")\n",
    "((data[\"Analysis\"].value_counts())/data.shape[0]).plot(kind = \"bar\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analysis: Monthly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "months = list(dict.fromkeys(data[\"Month\"].values))\n",
    "sentiments = list(dict.fromkeys(data[\"Analysis\"].values))\n",
    "sentiment_colors = {\"Positive\": \"Blue\", \"Negative\": \"Red\", \"Neutral\": \"Gray\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for month in months:\n",
    "    month_tweets = data.loc[data[\"Month\"] == month]\n",
    "    plt.title(\"Sentiment Analysis: \" + month)\n",
    "    plt.xlabel(\"Sentiment\")\n",
    "    plt.ylabel(\"Percentage of Total Tweets\")\n",
    "    ((month_tweets[\"Analysis\"].value_counts())/data.shape[0]).plot(kind = 'bar')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for sentiment in sentiments:\n",
    "    month_percentages = []\n",
    "    sentiment_tweets = data.loc[data[\"Analysis\"] == sentiment]\n",
    "    plt.title(\"Sentiment Analysis: \" + sentiment)\n",
    "    plt.xlabel(\"Sentiment\")\n",
    "    plt.ylabel(\"Percentage of Total Tweets\")\n",
    "    for month in months:\n",
    "        month_tweets = sentiment_tweets.loc[sentiment_tweets[\"Month\"] == month]\n",
    "        month_percentages.append(month_tweets[\"Analysis\"].value_counts()/data.shape[0])\n",
    "    plt.scatter(months, month_percentages) \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.title(\"Sentiment Analysis\")\n",
    "plt.xlabel(\"Sentiment\")\n",
    "plt.ylabel(\"Percentage of Total Tweets\")\n",
    "    \n",
    "for sentiment in sentiments:\n",
    "    month_percentages = []\n",
    "    sentiment_tweets = data.loc[data[\"Analysis\"] == sentiment]\n",
    "    for month in months:\n",
    "        month_tweets = sentiment_tweets.loc[sentiment_tweets[\"Month\"] == month]\n",
    "        month_percentages.append(month_tweets[\"Analysis\"].value_counts()/data.shape[0])\n",
    "    plt.scatter(months, month_percentages, c = sentiment_colors[sentiment]) \n",
    "    plt.plot(months, month_percentages, c = sentiment_colors[sentiment])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Naive Bayes Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = pd.read_csv(\"Data/full_corpus.csv\")\n",
    "\n",
    "corpus[\"TweetText\"] = corpus[\"TweetText\"].apply(cleanText)\n",
    "corpus[\"List of Words\"] = corpus[\"TweetText\"].apply(convertToList)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data, testing_data = train_test_split(corpus, test_size = 0.05)\n",
    "\n",
    "print(corpus.shape)\n",
    "print(training_data.shape)\n",
    "print(testing_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data_list = []\n",
    "for index, row in training_data.iterrows():\n",
    "    training_data_list.append((row[\"TweetText\"], row[\"Sentiment\"]))\n",
    "\n",
    "testing_data_list = []\n",
    "for index, row in testing_data.iterrows():\n",
    "    testing_data_list.append((row[\"TweetText\"], row[\"Sentiment\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function was adapted from https://towardsdatascience.com/creating-the-twitter-sentiment-analysis-program-in-python-with-naive-bayes-classification-672e5589a7ed\n",
    "# (The resource above is open source).\n",
    "def build(input_data):\n",
    "    world_list = []\n",
    "    \n",
    "    for (words, sentiment) in input_data:\n",
    "        world_list.extend(words)\n",
    "\n",
    "    words = nltk.FreqDist(world_list)\n",
    "    word_features = words.keys()\n",
    "    \n",
    "    return word_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function was adapted from https://towardsdatascience.com/creating-the-twitter-sentiment-analysis-program-in-python-with-naive-bayes-classification-672e5589a7ed\n",
    "# (The resource above is open source).\n",
    "def get_features(text):\n",
    "    words = set(text)\n",
    "    features = {}\n",
    "    \n",
    "    for word in word_features:\n",
    "        features['contains(%s)' % word] = (word in words)\n",
    "        \n",
    "    return features "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_features = build(training_data_list)\n",
    "training_features = nltk.classify.apply_features(get_features, training_data_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "naive_bayes_classifier = nltk.NaiveBayesClassifier.train(training_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This piece of code was suggested in https://towardsdatascience.com/creating-the-twitter-sentiment-analysis-program-in-python-with-naive-bayes-classification-672e5589a7ed\n",
    "classifier_result_labels = [naive_bayes_classifier.classify(get_features(tweet[0])) for tweet in testing_data_list]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Percentage of Positive Sentiments:\", classifier_result_labels.count('positive') / testing_data.shape[0])\n",
    "print()\n",
    "print(\"Percentage of Negative Sentiments:\", classifier_result_labels.count('negative') / testing_data.shape[0])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Applying the Model to Covid-19 Twitter Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training_data, testing_data = train_test_split(data, test_size = 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(data.shape)\n",
    "print(training_data.shape)\n",
    "print(testing_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# word_features = build(training_data_list)\n",
    "# training_features = nltk.classify.apply_features(get_features, training_data_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# naive_bayes_classifier = nltk.NaiveBayesClassifier.train(training_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This piece of code was suggested in https://towardsdatascience.com/creating-the-twitter-sentiment-analysis-program-in-python-with-naive-bayes-classification-672e5589a7ed\n",
    "covid_classifier_labels = [naive_bayes_classifier.classify(get_features(row[3])) for index, row in data.iterrows()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"Classification\"] = covid_classifier_labels\n",
    "data[\"Ensemble\"] = covid_classifier_labels # temporary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, row in data.iterrows():\n",
    "    if row[\"Polarity\"] < -0.2:\n",
    "        row[\"Ensemble\"] = \"negative\"\n",
    "    elif row[\"Polarity\"] > 0.2 and row[\"Classification\"] == \"neutral\":\n",
    "        row[\"Ensemble\"] = \"positive\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.loc[data[\"Polarity\"] < -0.2, \"Ensemble\"] = \"negative\"\n",
    "data.loc[data[\"Polarity\"] > 0.2, \"Ensemble\"] = \"positive\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(data[\"Ensemble\"].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Covid Cases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "confirmed = pd.read_csv('Data/covid_confirmed.csv')\n",
    "recovered = pd.read_csv('Data/covid_recovered.csv')\n",
    "deaths = pd.read_csv('Data/covid_deaths.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "confirmed.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "confirmed_us = confirmed.loc[confirmed[\"Country/Region\"] == \"US\"]\n",
    "deaths_us = deaths.loc[deaths[\"Country/Region\"] == \"US\"]\n",
    "recovered_us = recovered.loc[recovered[\"Country/Region\"] == \"US\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "confirmed_us.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_list = [confirmed_us, deaths_us, recovered_us]\n",
    "\n",
    "for i in range(3):\n",
    "    df = df_list[i].drop(columns = [\"Province/State\", \"Country/Region\", \"Lat\", \"Long\"])\n",
    "    dates, values = [], []\n",
    "\n",
    "    for j in df:\n",
    "        dates.append(j)\n",
    "        values.append(df.iloc[0][j])\n",
    "        \n",
    "    new_data = {'Date': dates, 'Cases': values}\n",
    "    df_list[i] = pd.DataFrame(new_data)\n",
    "\n",
    "confirmed_us = df_list[0]\n",
    "deaths_us = df_list[1]\n",
    "recovered_us = df_list[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "confirmed_us.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.title(\"Confirmed Cases - US\")\n",
    "plt.xlabel(\"Date\")\n",
    "plt.ylabel(\"Cases\")\n",
    "plt.plot(confirmed_us[\"Date\"], confirmed_us[\"Cases\"])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.title(\"Deaths - US\")\n",
    "plt.xlabel(\"Date\")\n",
    "plt.ylabel(\"Cases\")\n",
    "plt.plot(deaths_us[\"Date\"], deaths_us[\"Cases\"])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.title(\"Recovered - US\")\n",
    "plt.xlabel(\"Date\")\n",
    "plt.ylabel(\"Cases\")\n",
    "plt.plot(recovered_us[\"Date\"], recovered_us[\"Cases\"])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convertToWeekly(df):\n",
    "    new_dates, new_cases = [], []\n",
    "    count = 0\n",
    "\n",
    "    for index, row in df.iterrows():\n",
    "        if (count == 6):\n",
    "            new_dates.append(row[\"Date\"])\n",
    "            new_cases.append(row[\"Cases\"])\n",
    "            count = 0\n",
    "        else:\n",
    "            count += 1\n",
    "    \n",
    "    new_data = {'Date': new_dates, 'Cases': new_cases}\n",
    "    return pd.DataFrame(new_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "confirmed_us_weekly = convertToWeekly(confirmed_us)\n",
    "deaths_us_weekly = convertToWeekly(deaths_us)\n",
    "recovered_us_weekly = convertToWeekly(recovered_us)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "confirmed_us_weekly.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dates = list(confirmed_us_weekly[\"Date\"].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I realize that this is an incredibly inefficient function\n",
    "def getWeeklyResults(df):\n",
    "    results_list = []\n",
    "\n",
    "    for date in dates:\n",
    "        month = date[0:1]\n",
    "        day = \"\"\n",
    "        \n",
    "        if len(date) == 7:\n",
    "            day = date[2:4]\n",
    "        else:\n",
    "            day = date[2:3]\n",
    "                \n",
    "        date_results = []\n",
    "    \n",
    "        for index, row in df.iterrows():\n",
    "            tweet_date = row[\"Date\"]\n",
    "            tweet_month = date[0:1]\n",
    "            tweet_day = \"\" \n",
    "            \n",
    "            if len(tweet_date) == 7:\n",
    "                tweet_day = tweet_date[2:4]\n",
    "            else:\n",
    "                tweet_day = tweet_date[2:3]\n",
    "            \n",
    "            if tweet_month <= month:\n",
    "                if tweet_day <= day:\n",
    "                    date_results.append(row[\"Ensemble\"])\n",
    "        \n",
    "        results_list.append(date_results)\n",
    "    \n",
    "    return results_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weekly_results = getWeeklyResults(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(weekly_results[7]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "week_counts = {}\n",
    "for i in range(len(weekly_results)):\n",
    "    if (len(weekly_results[i]) != 0):\n",
    "        date = dates[i]\n",
    "        total_count = len(weekly_results[i])\n",
    "        counter = Counter(weekly_results[i])\n",
    "        positive_percent = counter[\"positive\"] / total_count\n",
    "        neutral_percent = counter[\"neutral\"] / total_count\n",
    "        negative_percent = counter[\"negative\"] / total_count\n",
    "        irrelevant_percent = counter[\"irrelevant\"] / total_count\n",
    "        week_counts[date] = [total_count, positive_percent, neutral_percent, negative_percent]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "week_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(df):\n",
    "    df[\"Normalized\"] = (df[\"Cases\"] - df[\"Cases\"].min()) / (df[\"Cases\"].max() - df[\"Cases\"].min())\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for df in [confirmed_us_weekly, recovered_us_weekly, deaths_us_weekly]:\n",
    "    df = normalize(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recovered_us.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def clean(df):\n",
    "    for index, row in df.iterrows():\n",
    "        if row[\"Date\"] not in week_counts:\n",
    "            df = df[df.Date != row[\"Date\"]]\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "confirmed_us_weekly = clean(confirmed_us_weekly)\n",
    "recovered_us_weekly = clean(recovered_us_weekly)\n",
    "deaths_us_weekly = clean(deaths_us_weekly)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def addTweetSentiment(df, i):\n",
    "    sentiment_list = []\n",
    "    \n",
    "    for index, row in df.iterrows():\n",
    "        if row[\"Date\"] in week_counts:\n",
    "            sentiments = week_counts[row[\"Date\"]]\n",
    "            sentiment_list.append(sentiments[i])\n",
    "        \n",
    "    df[str(i)] = sentiment_list\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(1, 4, 1):\n",
    "    confirmed_us_weekly = addTweetSentiment(confirmed_us_weekly, i)\n",
    "    recovered_us_weekly = addTweetSentiment(recovered_us_weekly, i)\n",
    "    deaths_us_weekly = addTweetSentiment(deaths_us_weekly, i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "confirmed_us_weekly.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams[\"figure.figsize\"] = (20,3)\n",
    "\n",
    "plt.title(\"Tweets and Confirmed Cases - US\")\n",
    "plt.xlabel(\"Date\")\n",
    "plt.ylabel(\"Percent\")\n",
    "\n",
    "plt.plot(confirmed_us_weekly[\"Date\"], confirmed_us_weekly[\"Normalized\"])\n",
    "for i in range(1, 4, 1):\n",
    "    plt.plot(confirmed_us_weekly[\"Date\"], confirmed_us_weekly[str(i)])\n",
    "plt.legend([\"Confirmed Cases\", \"Positive Tweets\", \"Neutral Tweets\", \"Negative Tweets\"])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams[\"figure.figsize\"] = (20,3)\n",
    "\n",
    "plt.title(\"Tweets and Deaths - US\")\n",
    "plt.xlabel(\"Date\")\n",
    "plt.ylabel(\"Percent\")\n",
    "\n",
    "plt.plot(confirmed_us_weekly[\"Date\"], confirmed_us_weekly[\"Normalized\"])\n",
    "for i in range(1, 4, 1):\n",
    "    plt.plot(confirmed_us_weekly[\"Date\"], confirmed_us_weekly[str(i)])\n",
    "plt.legend([\"Confirmed Cases\", \"Positive Tweets\", \"Neutral Tweets\", \"Negative Tweets\"])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams[\"figure.figsize\"] = (20,3)\n",
    "\n",
    "plt.title(\"Tweets and Recovered - US\")\n",
    "plt.xlabel(\"Date\")\n",
    "plt.ylabel(\"Percent\")\n",
    "\n",
    "plt.plot(confirmed_us_weekly[\"Date\"], confirmed_us_weekly[\"Normalized\"])\n",
    "for i in range(1, 4, 1):\n",
    "    plt.plot(confirmed_us_weekly[\"Date\"], confirmed_us_weekly[str(i)])\n",
    "plt.legend([\"Confirmed Cases\", \"Positive Tweets\", \"Neutral Tweets\", \"Negative Tweets\"])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "confirmed_us_weekly = confirmed_us_weekly.rename(columns = {\"1\": \"Positive Sentiment\", \"2\": \"Neutral Sentiment\", \"3\": \"Negative Sentiment\"})\n",
    "recovered_us_weekly = recovered_us_weekly.rename(columns = {\"1\": \"Positive Sentiment\", \"2\": \"Neutral Sentiment\", \"3\": \"Negative Sentiment\"})\n",
    "deaths_us_weekly = deaths_us_weekly.rename(columns = {\"1\": \"Positive Sentiment\", \"2\": \"Neutral Sentiment\", \"3\": \"Negative Sentiment\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "confirmed_us_weekly.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recovered_us_weekly.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "deaths_us_weekly.corr()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
